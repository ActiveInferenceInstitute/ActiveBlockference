{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38318d6e-b2a3-4330-8781-c3d5c1c54b4f",
   "metadata": {},
   "source": [
    "# Active Blockference Single Agent Revisited: Best Practices for Modular Blockference Development\n",
    "\n",
    "This notebook explores an alternative way of structuring the POMDP with a more granular approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65996f7b-9f83-4609-963d-8294a39d92b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccdb040-651d-4870-8471-8e1fd96946e9",
   "metadata": {},
   "source": [
    "The `Agent` class holds information about the generative model, i.e. ABCDE.\n",
    "\n",
    "The `Grid` class represents the environment, in this case a grid-world. \n",
    "\n",
    "The `environment` module will gradually have more environments that can be used in simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72100c92-f442-4949-b599-a2916c1ac886",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Grid()\n",
    "agent = Agent(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d1a9c0-249c-45d9-97a3-b928135a0528",
   "metadata": {},
   "source": [
    "The `Agent` takes `env` as input to get information about the number of observations and the dynamics of the environment, also whether it's globally observable (i.e. $A$ and $B$ stay fixed) or only locally observable (i.e. $A$ and $B$ will be updated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e49e89d-b6c6-4dfa-9d13-bcc7a0149956",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241m.\u001b[39mupdate(agent)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "env.update(agent) # takes either single agent or a list of agents, initialized the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a627d956-0385-429c-a586-3b32caa222ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    'agent': agent,\n",
    "    'env': env\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8b0b7f-ca9b-42b3-8250-f92263a918dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    initial_location: [], # run the simulation with a different initial location each time\n",
    "    preferred_location: [], # run the simulation with a different preferred location each time\n",
    "    barrier_location: [], # adding random barriers in the environment for the agent to avoid\n",
    "    policy_depth: [] # sweep over different planning depths\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7b9c40-afc0-4496-b878-aeff814fb4aa",
   "metadata": {},
   "source": [
    "### Policy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a624662-0a8e-4e0c-b849-f0b46d7ae5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_planning(params, substep, state_history, previous_state):\n",
    "    policies = construct_policies([act.n_states], [len(act.E)], policy_len = act.policy_len)\n",
    "    return 'update_policies': policies\n",
    "\n",
    "\n",
    "def p_actinf(params, substep, state_history, previous_state):\n",
    "    # get obs_idx\n",
    "    obs_idx = grid.index(previous_state['env_state'])\n",
    "\n",
    "    # infer_states\n",
    "    qs_current = u.infer_states(obs_idx, previous_state['prior_A'], previous_state['prior'])\n",
    "\n",
    "    # calc efe\n",
    "    policies = agent.policies\n",
    "    G = u.calculate_G_policies(previous_state['prior_A'], previous_state['prior_B'], previous_state['prior_C'], qs_current, policies=policies)\n",
    "\n",
    "    # calc action posterior\n",
    "    Q_pi = u.softmax(-G)\n",
    "\n",
    "    # compute the probability of each action\n",
    "    P_u = u.compute_prob_actions(act.E, policies, Q_pi)\n",
    "\n",
    "    # sample action\n",
    "    chosen_action = u.sample(P_u)\n",
    "\n",
    "    # calc next prior\n",
    "    prior = previous_state['prior_B'][:,:,chosen_action].dot(qs_current) \n",
    "\n",
    "    return {'update_prior': prior,\n",
    "            'update_action': chosen_action,\n",
    "            'update_inference': qs_current}\n",
    "\n",
    "def p_env(params, substep, state_history, previous_state):\n",
    "    \n",
    "    (Y, X) = previous_state['env_state']\n",
    "    Y_new = Y\n",
    "    X_new = X\n",
    "\n",
    "    if chosen_action == 0: # UP\n",
    "          \n",
    "        Y_new = Y - 1 if Y > 0 else Y\n",
    "        X_new = X\n",
    "\n",
    "    elif chosen_action == 1: # DOWN\n",
    "\n",
    "        Y_new = Y + 1 if Y < act.border else Y\n",
    "        X_new = X\n",
    "\n",
    "    elif chosen_action == 2: # LEFT\n",
    "        Y_new = Y\n",
    "        X_new = X - 1 if X > 0 else X\n",
    "\n",
    "    elif chosen_action == 3: # RIGHT\n",
    "        Y_new = Y\n",
    "        X_new = X +1 if X < act.border else X\n",
    "\n",
    "    elif chosen_action == 4: # STAY\n",
    "        Y_new, X_new = Y, X \n",
    "        \n",
    "    current_state = (Y_new, X_new) # store the new grid location\n",
    "    return 'update_env': current_state,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a80b072-2c4e-4d96-a56b-3cf12c4b93b9",
   "metadata": {},
   "source": [
    "## State Update Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d3f25c-0d75-453a-a6cc-943191c56250",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "block",
   "language": "python",
   "name": "block"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
